{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/profkalinowski/livroescd/blob/main/livro_ESCD_persistencia_e_implantacao_de_modelos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKU4syAPPUxT"
      },
      "source": [
        "# Engenharia de Software para Ciência de Dados - PUC-Rio\n",
        "\n",
        "### Persistindo e Carregando Modelos Treinados com Pickle e Joblib\n",
        "\n",
        "### Implantando um modelo em um endpoint na Google Cloud \n",
        "\n",
        "Marcos Kalinowski, Tatiana Escovedo, Hugo Villamizar e Hélio Lopes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa3eafljmpCz"
      },
      "source": [
        "## Persistindo e Carregando Modelos Treinados com Pickle e Joblib\n",
        "\n",
        "https://docs.python.org/2/library/pickle.html\n",
        "\n",
        "https://joblib.readthedocs.io/en/latest/\n",
        "\n",
        "É a maneira padrão de serializar objetos em Python, sendo possível serializar modelos de aprendizado de máquina e salvar o formato serializado em um arquivo. Posteriormente, é possível pode carregar esse arquivo para desserializar o modelo e usá-lo para fazer novas previsões.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import das bibliotecas que serão usadas para criar um modelo de ML\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import joblib\n",
        "from sklearn import datasets\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Arvg9yJwEkHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregando um dataset que será usado para treinar um modelo"
      ],
      "metadata": {
        "id": "eNMDCRqIl0ZO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT2KnwJaZcxR"
      },
      "source": [
        "# Informa a URL de importação do dataset\n",
        "url = \"https://raw.githubusercontent.com/tatianaesc/datascience/main/diabetes.csv\"\n",
        "\n",
        "# Informa o cabeçalho das colunas\n",
        "colunas = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "\n",
        "# Lê o arquivo utilizando as colunas informadas\n",
        "dataset = pd.read_csv(url, names=colunas, skiprows=1, delimiter=',')\n",
        "\n",
        "# Pega apenas os dados do dataset e guardando em um array\n",
        "array = dataset.values\n",
        "\n",
        "# Separa o array em variáveis preditoras (X) e variável target (Y)\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dividindo os dados em treino e teste para treinar um modelo de ML usando o algoritmo LogisticRegression "
      ],
      "metadata": {
        "id": "TKhFm-dwnQEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Divide os dados em treino e teste\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
        "\n",
        "# Cria o modelo\n",
        "modelo = LogisticRegression(solver='liblinear') \n",
        "\n",
        "# Treina o modelo\n",
        "modelo.fit(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ts6wsKUlFmZx",
        "outputId": "61f0fc56-ab9f-4aee-c6f5-d55978b157a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(solver='liblinear')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Salvando o modelo usando a biblioteca Picke"
      ],
      "metadata": {
        "id": "7DfAOw8CnvOb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtyMRxq1mpJm"
      },
      "source": [
        "artifact_pkl_filename = 'model.pkl'\n",
        "\n",
        "local_path = artifact_pkl_filename\n",
        "with open(local_path, 'wb') as model_file:\n",
        "  pickle.dump(modelo, model_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Salvando o mesmo modelo usando a biblioteca Joblib"
      ],
      "metadata": {
        "id": "Ykdk8JHVoXV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "artifact_joblib_filename = 'model.joblib'\n",
        "\n",
        "local_path = artifact_joblib_filename\n",
        "joblib.dump(modelo, local_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcK1cfUcLgkc",
        "outputId": "7091bc28-ff12-439c-9bb3-56c3210a3e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carrega ambos os modelos do disco e avalia eles usando os dados de teste"
      ],
      "metadata": {
        "id": "BXQmAxB5o2kJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pickle\n",
        "loaded_pkl_model = pickle.load(open(artifact_pkl_filename, 'rb'))\n",
        "\n",
        "# Joblib\n",
        "loaded_joblib_model = joblib.load(artifact_joblib_filename)\n",
        "\n",
        "# Avaliando os modelos carregados com os dados de teste\n",
        "pkl_results = loaded_pkl_model.score(X_test, Y_test) \n",
        "print('Pickle: ', pkl_results)\n",
        "\n",
        "joblib_results = loaded_joblib_model.score(X_test, Y_test) \n",
        "print('Joblib: ', joblib_results)"
      ],
      "metadata": {
        "id": "T-lt9RrHF6qf",
        "outputId": "3dc4ed93-a4cd-48e7-d715-c1c34a480d00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pickle:  0.7559055118110236\n",
            "Joblib:  0.7559055118110236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usando o modelo carregado para obter previsões"
      ],
      "metadata": {
        "id": "594PJToCqMhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_pkl_model.predict(X_test[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hFegxVnDdDm",
        "outputId": "59bd4084-2fa3-4749-f999-f3f85dc17c06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 1., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_joblib_model.predict(X_test[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzfrgAA9qnS1",
        "outputId": "b724cd30-f31b-4f0f-f60c-2d1c9df1ef07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 1., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implantando um modelo em um endpoint na Google Cloud\n",
        "\n",
        "https://github.com/googleapis/python-aiplatform\n",
        "\n",
        "Para usar os serviços de computação em nuvem da Google e outras plataformas é necessário ter uma conta ativa. A maioria dos serviços de armazenamento e processamento são pagos. Porém, no caso da Google, cada usuário novo tem um crédito de 300 dólares que pode ser usado em até 3 meses. "
      ],
      "metadata": {
        "id": "x18neRvPd4CF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-aiplatform"
      ],
      "metadata": {
        "id": "jtYArFg1vtMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bibliotecas para conectar com a google cloud\n",
        "# Importante: instalar a biblioteca --> pip install google-cloud-aiplatform\n",
        "from google.cloud import aiplatform\n",
        "from google.cloud import storage\n",
        "from google.oauth2 import service_account"
      ],
      "metadata": {
        "id": "s_MAK2PWvjC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conectando com a plataforma de computação da Google"
      ],
      "metadata": {
        "id": "FuPWZvHTvEgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "google_cloud_credentials = service_account.Credentials.from_service_account_file('google_cloud_secrets.json')"
      ],
      "metadata": {
        "id": "s6TIVJWj48hM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Usando** o modulo 'storage' para conectar com o serviço de armazenamento da Google Cloud"
      ],
      "metadata": {
        "id": "XuLnVRLtvGp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "project_id = 'project_id'\n",
        "storage_client = storage.Client(project=project_id, credentials=google_cloud_credentials)"
      ],
      "metadata": {
        "id": "nBn0lV5UvHrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usando o método 'bucket' do objeto 'storage_client' para armazenar o modelo que foi exportado usando a biblioteca Pickle"
      ],
      "metadata": {
        "id": "qZuRiQQUwclw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Especificando o nome do bucket e do arquivo que será armazenado\n",
        "bucket_name = 'models-teste'\n",
        "model_name =  'model.pkl'\n",
        "\n",
        "# Conectando com o bucket especificado\n",
        "bucket = storage_client.bucket(bucket_name)\n",
        "\n",
        "# Especificando o caminho onde será salvo o arquivo dentro do bucket\n",
        "destination_blob_name = 'model/{}'.format(bucket_name)\n",
        "\n",
        "# Fazendo o upload do arquivo no bucket\n",
        "blob = bucket.blob(destination_blob_name)\n",
        "blob.upload_from_filename(model_name)\n",
        "\n",
        "print(f\"Arquivo {model_name} carregado no caminho {destination_blob_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtqI_ARYgIGO",
        "outputId": "6ae8dbb6-5e11-4247-afa8-addf0f876729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo model.pkl carregado no caminho model/models-hugo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicializando o workspace de inteligencia artificial da Google Cloud para registrar um modelo e criar um endpoint"
      ],
      "metadata": {
        "id": "TOE4GX1X01gY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Especificando a região\n",
        "region = 'us-east1'\n",
        "\n",
        "# Init vertex ai\n",
        "aiplatform.init(project=project_id, location=region, credentials=google_cloud_credentials, staging_bucket='gs://models-teste')"
      ],
      "metadata": {
        "id": "i5gaGF1YjO_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importando um modelo, neste caso, o modelo exportado usando a biblioteca Pickle, no workspace de inteligencia artificial da Google"
      ],
      "metadata": {
        "id": "l9njbIaK1hAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = aiplatform.Model.upload(display_name = 'logistic-regression-model-v1',\n",
        "    description = 'Modelo de teste',\n",
        "    artifact_uri = 'gs://models-teste/model/',\n",
        "    serving_container_image_uri = 'us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-0:latest'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MszZ_YymnJ36",
        "outputId": "8d224a17-06fe-4184-eac9-e1d2f7d4b0b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.models:Creating Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create Model backing LRO: projects/962955980454/locations/us-east1/models/6979400745959292928/operations/8880230950500302848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.models:Create Model backing LRO: projects/962955980454/locations/us-east1/models/6979400745959292928/operations/8880230950500302848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model created. Resource name: projects/962955980454/locations/us-east1/models/6979400745959292928@1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.models:Model created. Resource name: projects/962955980454/locations/us-east1/models/6979400745959292928@1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To use this Model in another session:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.models:To use this Model in another session:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model = aiplatform.Model('projects/962955980454/locations/us-east1/models/6979400745959292928@1')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.models:model = aiplatform.Model('projects/962955980454/locations/us-east1/models/6979400745959292928@1')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criando um endpoint no workspace de inteligencia artificial da Google onde será hospedado o nosso modelo"
      ],
      "metadata": {
        "id": "StCNXSUA2Yg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and endpoint\n",
        "endpoint = aiplatform.Endpoint.create(display_name = 'logistic_regression_endpoint', \n",
        "                                      project = project_id, \n",
        "                                      location = region)"
      ],
      "metadata": {
        "id": "a9oJzzi5yzxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61daf52d-c12a-4b6d-e30a-1607853d8c5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Endpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.models:Creating Endpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create Endpoint backing LRO: projects/962955980454/locations/us-east1/endpoints/1153009465537069056/operations/7170551941959778304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.models:Create Endpoint backing LRO: projects/962955980454/locations/us-east1/endpoints/1153009465537069056/operations/7170551941959778304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Endpoint created. Resource name: projects/962955980454/locations/us-east1/endpoints/1153009465537069056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.models:Endpoint created. Resource name: projects/962955980454/locations/us-east1/endpoints/1153009465537069056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To use this Endpoint in another session:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.models:To use this Endpoint in another session:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "endpoint = aiplatform.Endpoint('projects/962955980454/locations/us-east1/endpoints/1153009465537069056')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.models:endpoint = aiplatform.Endpoint('projects/962955980454/locations/us-east1/endpoints/1153009465537069056')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implantação do modelo no endpoint que foi criado"
      ],
      "metadata": {
        "id": "-b-WGQu523vE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint.deploy(model, machine_type='n1-standard-2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adGkavub59Bc",
        "outputId": "090353e3-13e0-469a-d390-0c4367e8a46f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deploying Model projects/962955980454/locations/us-east1/models/6979400745959292928 to Endpoint : projects/962955980454/locations/us-east1/endpoints/1153009465537069056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.models:Deploying Model projects/962955980454/locations/us-east1/models/6979400745959292928 to Endpoint : projects/962955980454/locations/us-east1/endpoints/1153009465537069056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deploy Endpoint model backing LRO: projects/962955980454/locations/us-east1/endpoints/1153009465537069056/operations/2437831683546808320\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.models:Deploy Endpoint model backing LRO: projects/962955980454/locations/us-east1/endpoints/1153009465537069056/operations/2437831683546808320\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Endpoint model deployed. Resource name: projects/962955980454/locations/us-east1/endpoints/1153009465537069056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.models:Endpoint model deployed. Resource name: projects/962955980454/locations/us-east1/endpoints/1153009465537069056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtendo previsões do endpoint que foi implantando na Google Cloud. Veja que foram passados os mesmos dados de teste dos modelos exportados como arquivos. "
      ],
      "metadata": {
        "id": "fqtlGCqX3N81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint.predict(X_test.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USf35gKY_1Wo",
        "outputId": "b600dc4e-3c43-4248-b12f-de77bc7fe0f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Prediction(predictions=[0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0], deployed_model_id='1332731238166822912', model_version_id='1', model_resource_name='projects/962955980454/locations/us-east1/models/6979400745959292928', explanations=None)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3ebcZd8XERtK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}